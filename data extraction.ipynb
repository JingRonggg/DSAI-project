{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacffec8",
   "metadata": {},
   "source": [
    "### Importing Essential Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d64f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INKY\\AppData\\Local\\Temp\\ipykernel_26276\\389246638.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\INKY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\INKY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\INKY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19efeb0b",
   "metadata": {},
   "source": [
    "### Import the Instagram Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d4a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Datasets/Instagram data.csv\", encoding = \"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a59901",
   "metadata": {},
   "source": [
    "### Cleaning the Instagram Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae956bae",
   "metadata": {},
   "source": [
    " Checking if dataset has any missing values (NULL vales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4628a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coloumn name: Impressions - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: From Home - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: From Hashtags - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: From Explore - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: From Other - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Saves - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Comments - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Shares - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Likes - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Profile Visits - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Follows - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Caption - missing values 0\n",
      "----------------------------------------------------------------------\n",
      "coloumn name: Hashtags - missing values 0\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in data:\n",
    "    print(\"coloumn name:\", column, \"- missing values\", data[column].isnull().sum())\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dafc0262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impressions</th>\n",
       "      <th>From Home</th>\n",
       "      <th>From Hashtags</th>\n",
       "      <th>From Explore</th>\n",
       "      <th>From Other</th>\n",
       "      <th>Saves</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Profile Visits</th>\n",
       "      <th>Follows</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3920</td>\n",
       "      <td>2586</td>\n",
       "      <td>1028</td>\n",
       "      <td>619</td>\n",
       "      <td>56</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>Here are some of the most important data visua...</td>\n",
       "      <td>#finance #money #business #investing #investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5394</td>\n",
       "      <td>2727</td>\n",
       "      <td>1838</td>\n",
       "      <td>1174</td>\n",
       "      <td>78</td>\n",
       "      <td>194</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>Here are some of the best data science project...</td>\n",
       "      <td>#healthcare #health #covid #data #datascience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4021</td>\n",
       "      <td>2085</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>Learn how to train a machine learning model an...</td>\n",
       "      <td>#data #datascience #dataanalysis #dataanalytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4528</td>\n",
       "      <td>2700</td>\n",
       "      <td>621</td>\n",
       "      <td>932</td>\n",
       "      <td>73</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>Heres how you can write a Python program to d...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2518</td>\n",
       "      <td>1704</td>\n",
       "      <td>255</td>\n",
       "      <td>279</td>\n",
       "      <td>37</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Plotting annotations while visualizing your da...</td>\n",
       "      <td>#datavisualization #datascience #data #dataana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Impressions  From Home  From Hashtags  From Explore  From Other  Saves  \\\n",
       "0         3920       2586           1028           619          56     98   \n",
       "1         5394       2727           1838          1174          78    194   \n",
       "2         4021       2085           1188             0         533     41   \n",
       "3         4528       2700            621           932          73    172   \n",
       "4         2518       1704            255           279          37     96   \n",
       "\n",
       "   Comments  Shares  Likes  Profile Visits  Follows  \\\n",
       "0         9       5    162              35        2   \n",
       "1         7      14    224              48       10   \n",
       "2        11       1    131              62       12   \n",
       "3        10       7    213              23        8   \n",
       "4         5       4    123               8        0   \n",
       "\n",
       "                                             Caption  \\\n",
       "0  Here are some of the most important data visua...   \n",
       "1  Here are some of the best data science project...   \n",
       "2  Learn how to train a machine learning model an...   \n",
       "3  Heres how you can write a Python program to d...   \n",
       "4  Plotting annotations while visualizing your da...   \n",
       "\n",
       "                                            Hashtags  \n",
       "0  #finance #money #business #investing #investme...  \n",
       "1  #healthcare #health #covid #data #datascience ...  \n",
       "2  #data #datascience #dataanalysis #dataanalytic...  \n",
       "3  #python #pythonprogramming #pythonprojects #py...  \n",
       "4  #datavisualization #datascience #data #dataana...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef82b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119 entries, 0 to 118\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Impressions     119 non-null    int64 \n",
      " 1   From Home       119 non-null    int64 \n",
      " 2   From Hashtags   119 non-null    int64 \n",
      " 3   From Explore    119 non-null    int64 \n",
      " 4   From Other      119 non-null    int64 \n",
      " 5   Saves           119 non-null    int64 \n",
      " 6   Comments        119 non-null    int64 \n",
      " 7   Shares          119 non-null    int64 \n",
      " 8   Likes           119 non-null    int64 \n",
      " 9   Profile Visits  119 non-null    int64 \n",
      " 10  Follows         119 non-null    int64 \n",
      " 11  Caption         119 non-null    object\n",
      " 12  Hashtags        119 non-null    object\n",
      "dtypes: int64(11), object(2)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58938304",
   "metadata": {},
   "source": [
    " Removing `From Home` `From Hashtags` `From Explore`\t`From Other` `Saves` `Profile Visits` `Follows` from the data set as our Main question do not require data from these 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2aa7254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3920</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>Here are some of the most important data visua...</td>\n",
       "      <td>#finance #money #business #investing #investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5394</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>Here are some of the best data science project...</td>\n",
       "      <td>#healthcare #health #covid #data #datascience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4021</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>Learn how to train a machine learning model an...</td>\n",
       "      <td>#data #datascience #dataanalysis #dataanalytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4528</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>213</td>\n",
       "      <td>Heres how you can write a Python program to d...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2518</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>Plotting annotations while visualizing your da...</td>\n",
       "      <td>#datavisualization #datascience #data #dataana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>13700</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>373</td>\n",
       "      <td>Here are some of the best data science certifi...</td>\n",
       "      <td>#datascience #datasciencejobs #datasciencetrai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5731</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>Clustering is a machine learning technique use...</td>\n",
       "      <td>#machinelearning #machinelearningalgorithms #d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>Clustering music genres is a task of grouping ...</td>\n",
       "      <td>#machinelearning #machinelearningalgorithms #d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>32695</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>549</td>\n",
       "      <td>Here are some of the best data science certifi...</td>\n",
       "      <td>#datascience #datasciencejobs #datasciencetrai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>36919</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>443</td>\n",
       "      <td>175 Python Projects with Source Code solved an...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Impressions  Comments  Shares  Likes  \\\n",
       "0           3920         9       5    162   \n",
       "1           5394         7      14    224   \n",
       "2           4021        11       1    131   \n",
       "3           4528        10       7    213   \n",
       "4           2518         5       4    123   \n",
       "..           ...       ...     ...    ...   \n",
       "114        13700         2      38    373   \n",
       "115         5731         4       1    148   \n",
       "116         4139         0       1     92   \n",
       "117        32695         2      75    549   \n",
       "118        36919         5      26    443   \n",
       "\n",
       "                                               Caption  \\\n",
       "0    Here are some of the most important data visua...   \n",
       "1    Here are some of the best data science project...   \n",
       "2    Learn how to train a machine learning model an...   \n",
       "3    Heres how you can write a Python program to d...   \n",
       "4    Plotting annotations while visualizing your da...   \n",
       "..                                                 ...   \n",
       "114  Here are some of the best data science certifi...   \n",
       "115  Clustering is a machine learning technique use...   \n",
       "116  Clustering music genres is a task of grouping ...   \n",
       "117  Here are some of the best data science certifi...   \n",
       "118  175 Python Projects with Source Code solved an...   \n",
       "\n",
       "                                              Hashtags  \n",
       "0    #finance #money #business #investing #investme...  \n",
       "1    #healthcare #health #covid #data #datascience ...  \n",
       "2    #data #datascience #dataanalysis #dataanalytic...  \n",
       "3    #python #pythonprogramming #pythonprojects #py...  \n",
       "4    #datavisualization #datascience #data #dataana...  \n",
       "..                                                 ...  \n",
       "114  #datascience #datasciencejobs #datasciencetrai...  \n",
       "115  #machinelearning #machinelearningalgorithms #d...  \n",
       "116  #machinelearning #machinelearningalgorithms #d...  \n",
       "117  #datascience #datasciencejobs #datasciencetrai...  \n",
       "118  #python #pythonprogramming #pythonprojects #py...  \n",
       "\n",
       "[119 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['From Home','From Hashtags','From Explore', 'From Other','Saves', 'Profile Visits', 'Follows'], axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54225577",
   "metadata": {},
   "source": [
    "Performing data cleaning on Unstructured data using Natural Language Processing. \n",
    "This is done by doing stemming and lemmatization on the caption column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a6ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionDF = data\n",
    "captionDF['fullCaption'] = captionDF['Caption'] + ' ' + data['Hashtags']\n",
    "captionDF['fullCaption'] = captionDF['fullCaption'].apply(lambda x: str(x).replace(u'\\xa0', u' '))\n",
    "captionDF['fullCaption'] = captionDF['fullCaption'].apply(lambda x: str(x).lower())\n",
    "captionDF['fullCaption'][0]\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Stemming function\n",
    "def stem_tokens(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Lemmatization function\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "df = captionDF\n",
    "# Apply tokenization, remove stopwords, and perform stemming or lemmatization\n",
    "df['Tokenized_Text'] = df['fullCaption'].apply(tokenize_text)\n",
    "df['Stemmed_Text'] = df['Tokenized_Text'].apply(stem_tokens)\n",
    "df['tokenizedCaptions'] = df['Stemmed_Text'].apply(lemmatize_tokens)\n",
    "\n",
    "# Apply tokenization, remove stopwords, and perform stemming or lemmatization\n",
    "df['Tokenized_Hashtags'] = df['Hashtags'].apply(tokenize_text)\n",
    "df['Stemmed_Hashtags'] = df['Tokenized_Hashtags'].apply(stem_tokens)\n",
    "df['tokenizedHashtags'] = df['Stemmed_Hashtags'].apply(lemmatize_tokens)\n",
    "\n",
    "captionDF = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f35093d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>fullCaption</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>tokenizedCaptions</th>\n",
       "      <th>Tokenized_Hashtags</th>\n",
       "      <th>Stemmed_Hashtags</th>\n",
       "      <th>tokenizedHashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3920</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>Here are some of the most important data visua...</td>\n",
       "      <td>#finance #money #business #investing #investme...</td>\n",
       "      <td>here are some of the most important data visua...</td>\n",
       "      <td>[important, data, visualizations, every, finan...</td>\n",
       "      <td>[import, data, visual, everi, financi, data, a...</td>\n",
       "      <td>[import, data, visual, everi, financi, data, a...</td>\n",
       "      <td>[finance, money, business, investing, investme...</td>\n",
       "      <td>[financ, money, busi, invest, invest, trade, s...</td>\n",
       "      <td>[financ, money, busi, invest, invest, trade, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5394</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>Here are some of the best data science project...</td>\n",
       "      <td>#healthcare #health #covid #data #datascience ...</td>\n",
       "      <td>here are some of the best data science project...</td>\n",
       "      <td>[best, data, science, project, ideas, healthca...</td>\n",
       "      <td>[best, data, scienc, project, idea, healthcar,...</td>\n",
       "      <td>[best, data, scienc, project, idea, healthcar,...</td>\n",
       "      <td>[healthcare, health, covid, data, datascience,...</td>\n",
       "      <td>[healthcar, health, covid, data, datasci, data...</td>\n",
       "      <td>[healthcar, health, covid, data, datasci, data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4021</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>Learn how to train a machine learning model an...</td>\n",
       "      <td>#data #datascience #dataanalysis #dataanalytic...</td>\n",
       "      <td>learn how to train a machine learning model an...</td>\n",
       "      <td>[learn, train, machine, learning, model, givin...</td>\n",
       "      <td>[learn, train, machin, learn, model, give, inp...</td>\n",
       "      <td>[learn, train, machin, learn, model, give, inp...</td>\n",
       "      <td>[data, datascience, dataanalysis, dataanalytic...</td>\n",
       "      <td>[data, datasci, dataanalysi, dataanalyt, datas...</td>\n",
       "      <td>[data, datasci, dataanalysi, dataanalyt, datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4528</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>213</td>\n",
       "      <td>Heres how you can write a Python program to d...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "      <td>heres how you can write a python program to d...</td>\n",
       "      <td>[heres, write, python, program, detect, whethe...</td>\n",
       "      <td>[here, write, python, program, detect, whether...</td>\n",
       "      <td>[here, write, python, program, detect, whether...</td>\n",
       "      <td>[python, pythonprogramming, pythonprojects, py...</td>\n",
       "      <td>[python, pythonprogram, pythonproject, pythonc...</td>\n",
       "      <td>[python, pythonprogram, pythonproject, pythonc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2518</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>Plotting annotations while visualizing your da...</td>\n",
       "      <td>#datavisualization #datascience #data #dataana...</td>\n",
       "      <td>plotting annotations while visualizing your da...</td>\n",
       "      <td>[plotting, annotations, visualizing, data, con...</td>\n",
       "      <td>[plot, annot, visual, data, consid, good, prac...</td>\n",
       "      <td>[plot, annot, visual, data, consid, good, prac...</td>\n",
       "      <td>[datavisualization, datascience, data, dataana...</td>\n",
       "      <td>[datavisu, datasci, data, dataanalyt, machinel...</td>\n",
       "      <td>[datavisu, datasci, data, dataanalyt, machinel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>13700</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>373</td>\n",
       "      <td>Here are some of the best data science certifi...</td>\n",
       "      <td>#datascience #datasciencejobs #datasciencetrai...</td>\n",
       "      <td>here are some of the best data science certifi...</td>\n",
       "      <td>[best, data, science, certifications, choose, ...</td>\n",
       "      <td>[best, data, scienc, certif, choos, datasci, d...</td>\n",
       "      <td>[best, data, scienc, certif, choos, datasci, d...</td>\n",
       "      <td>[datascience, datasciencejobs, datasciencetrai...</td>\n",
       "      <td>[datasci, datasciencejob, datasciencetrain, da...</td>\n",
       "      <td>[datasci, datasciencejob, datasciencetrain, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5731</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>Clustering is a machine learning technique use...</td>\n",
       "      <td>#machinelearning #machinelearningalgorithms #d...</td>\n",
       "      <td>clustering is a machine learning technique use...</td>\n",
       "      <td>[clustering, machine, learning, technique, use...</td>\n",
       "      <td>[cluster, machin, learn, techniqu, use, classi...</td>\n",
       "      <td>[cluster, machin, learn, techniqu, use, classi...</td>\n",
       "      <td>[machinelearning, machinelearningalgorithms, d...</td>\n",
       "      <td>[machinelearn, machinelearningalgorithm, datas...</td>\n",
       "      <td>[machinelearn, machinelearningalgorithm, datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>Clustering music genres is a task of grouping ...</td>\n",
       "      <td>#machinelearning #machinelearningalgorithms #d...</td>\n",
       "      <td>clustering music genres is a task of grouping ...</td>\n",
       "      <td>[clustering, music, genres, task, grouping, mu...</td>\n",
       "      <td>[cluster, music, genr, task, group, music, bas...</td>\n",
       "      <td>[cluster, music, genr, task, group, music, bas...</td>\n",
       "      <td>[machinelearning, machinelearningalgorithms, d...</td>\n",
       "      <td>[machinelearn, machinelearningalgorithm, datas...</td>\n",
       "      <td>[machinelearn, machinelearningalgorithm, datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>32695</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>549</td>\n",
       "      <td>Here are some of the best data science certifi...</td>\n",
       "      <td>#datascience #datasciencejobs #datasciencetrai...</td>\n",
       "      <td>here are some of the best data science certifi...</td>\n",
       "      <td>[best, data, science, certifications, choose, ...</td>\n",
       "      <td>[best, data, scienc, certif, choos, datasci, d...</td>\n",
       "      <td>[best, data, scienc, certif, choos, datasci, d...</td>\n",
       "      <td>[datascience, datasciencejobs, datasciencetrai...</td>\n",
       "      <td>[datasci, datasciencejob, datasciencetrain, da...</td>\n",
       "      <td>[datasci, datasciencejob, datasciencetrain, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>36919</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>443</td>\n",
       "      <td>175 Python Projects with Source Code solved an...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "      <td>175 python projects with source code solved an...</td>\n",
       "      <td>[python, projects, source, code, solved, expla...</td>\n",
       "      <td>[python, project, sourc, code, solv, explain, ...</td>\n",
       "      <td>[python, project, sourc, code, solv, explain, ...</td>\n",
       "      <td>[python, pythonprogramming, pythonprojects, py...</td>\n",
       "      <td>[python, pythonprogram, pythonproject, pythonc...</td>\n",
       "      <td>[python, pythonprogram, pythonproject, pythonc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Impressions  Comments  Shares  Likes  \\\n",
       "0           3920         9       5    162   \n",
       "1           5394         7      14    224   \n",
       "2           4021        11       1    131   \n",
       "3           4528        10       7    213   \n",
       "4           2518         5       4    123   \n",
       "..           ...       ...     ...    ...   \n",
       "114        13700         2      38    373   \n",
       "115         5731         4       1    148   \n",
       "116         4139         0       1     92   \n",
       "117        32695         2      75    549   \n",
       "118        36919         5      26    443   \n",
       "\n",
       "                                               Caption  \\\n",
       "0    Here are some of the most important data visua...   \n",
       "1    Here are some of the best data science project...   \n",
       "2    Learn how to train a machine learning model an...   \n",
       "3    Heres how you can write a Python program to d...   \n",
       "4    Plotting annotations while visualizing your da...   \n",
       "..                                                 ...   \n",
       "114  Here are some of the best data science certifi...   \n",
       "115  Clustering is a machine learning technique use...   \n",
       "116  Clustering music genres is a task of grouping ...   \n",
       "117  Here are some of the best data science certifi...   \n",
       "118  175 Python Projects with Source Code solved an...   \n",
       "\n",
       "                                              Hashtags  \\\n",
       "0    #finance #money #business #investing #investme...   \n",
       "1    #healthcare #health #covid #data #datascience ...   \n",
       "2    #data #datascience #dataanalysis #dataanalytic...   \n",
       "3    #python #pythonprogramming #pythonprojects #py...   \n",
       "4    #datavisualization #datascience #data #dataana...   \n",
       "..                                                 ...   \n",
       "114  #datascience #datasciencejobs #datasciencetrai...   \n",
       "115  #machinelearning #machinelearningalgorithms #d...   \n",
       "116  #machinelearning #machinelearningalgorithms #d...   \n",
       "117  #datascience #datasciencejobs #datasciencetrai...   \n",
       "118  #python #pythonprogramming #pythonprojects #py...   \n",
       "\n",
       "                                           fullCaption  \\\n",
       "0    here are some of the most important data visua...   \n",
       "1    here are some of the best data science project...   \n",
       "2    learn how to train a machine learning model an...   \n",
       "3    heres how you can write a python program to d...   \n",
       "4    plotting annotations while visualizing your da...   \n",
       "..                                                 ...   \n",
       "114  here are some of the best data science certifi...   \n",
       "115  clustering is a machine learning technique use...   \n",
       "116  clustering music genres is a task of grouping ...   \n",
       "117  here are some of the best data science certifi...   \n",
       "118  175 python projects with source code solved an...   \n",
       "\n",
       "                                        Tokenized_Text  \\\n",
       "0    [important, data, visualizations, every, finan...   \n",
       "1    [best, data, science, project, ideas, healthca...   \n",
       "2    [learn, train, machine, learning, model, givin...   \n",
       "3    [heres, write, python, program, detect, whethe...   \n",
       "4    [plotting, annotations, visualizing, data, con...   \n",
       "..                                                 ...   \n",
       "114  [best, data, science, certifications, choose, ...   \n",
       "115  [clustering, machine, learning, technique, use...   \n",
       "116  [clustering, music, genres, task, grouping, mu...   \n",
       "117  [best, data, science, certifications, choose, ...   \n",
       "118  [python, projects, source, code, solved, expla...   \n",
       "\n",
       "                                          Stemmed_Text  \\\n",
       "0    [import, data, visual, everi, financi, data, a...   \n",
       "1    [best, data, scienc, project, idea, healthcar,...   \n",
       "2    [learn, train, machin, learn, model, give, inp...   \n",
       "3    [here, write, python, program, detect, whether...   \n",
       "4    [plot, annot, visual, data, consid, good, prac...   \n",
       "..                                                 ...   \n",
       "114  [best, data, scienc, certif, choos, datasci, d...   \n",
       "115  [cluster, machin, learn, techniqu, use, classi...   \n",
       "116  [cluster, music, genr, task, group, music, bas...   \n",
       "117  [best, data, scienc, certif, choos, datasci, d...   \n",
       "118  [python, project, sourc, code, solv, explain, ...   \n",
       "\n",
       "                                     tokenizedCaptions  \\\n",
       "0    [import, data, visual, everi, financi, data, a...   \n",
       "1    [best, data, scienc, project, idea, healthcar,...   \n",
       "2    [learn, train, machin, learn, model, give, inp...   \n",
       "3    [here, write, python, program, detect, whether...   \n",
       "4    [plot, annot, visual, data, consid, good, prac...   \n",
       "..                                                 ...   \n",
       "114  [best, data, scienc, certif, choos, datasci, d...   \n",
       "115  [cluster, machin, learn, techniqu, use, classi...   \n",
       "116  [cluster, music, genr, task, group, music, bas...   \n",
       "117  [best, data, scienc, certif, choos, datasci, d...   \n",
       "118  [python, project, sourc, code, solv, explain, ...   \n",
       "\n",
       "                                    Tokenized_Hashtags  \\\n",
       "0    [finance, money, business, investing, investme...   \n",
       "1    [healthcare, health, covid, data, datascience,...   \n",
       "2    [data, datascience, dataanalysis, dataanalytic...   \n",
       "3    [python, pythonprogramming, pythonprojects, py...   \n",
       "4    [datavisualization, datascience, data, dataana...   \n",
       "..                                                 ...   \n",
       "114  [datascience, datasciencejobs, datasciencetrai...   \n",
       "115  [machinelearning, machinelearningalgorithms, d...   \n",
       "116  [machinelearning, machinelearningalgorithms, d...   \n",
       "117  [datascience, datasciencejobs, datasciencetrai...   \n",
       "118  [python, pythonprogramming, pythonprojects, py...   \n",
       "\n",
       "                                      Stemmed_Hashtags  \\\n",
       "0    [financ, money, busi, invest, invest, trade, s...   \n",
       "1    [healthcar, health, covid, data, datasci, data...   \n",
       "2    [data, datasci, dataanalysi, dataanalyt, datas...   \n",
       "3    [python, pythonprogram, pythonproject, pythonc...   \n",
       "4    [datavisu, datasci, data, dataanalyt, machinel...   \n",
       "..                                                 ...   \n",
       "114  [datasci, datasciencejob, datasciencetrain, da...   \n",
       "115  [machinelearn, machinelearningalgorithm, datas...   \n",
       "116  [machinelearn, machinelearningalgorithm, datas...   \n",
       "117  [datasci, datasciencejob, datasciencetrain, da...   \n",
       "118  [python, pythonprogram, pythonproject, pythonc...   \n",
       "\n",
       "                                     tokenizedHashtags  \n",
       "0    [financ, money, busi, invest, invest, trade, s...  \n",
       "1    [healthcar, health, covid, data, datasci, data...  \n",
       "2    [data, datasci, dataanalysi, dataanalyt, datas...  \n",
       "3    [python, pythonprogram, pythonproject, pythonc...  \n",
       "4    [datavisu, datasci, data, dataanalyt, machinel...  \n",
       "..                                                 ...  \n",
       "114  [datasci, datasciencejob, datasciencetrain, da...  \n",
       "115  [machinelearn, machinelearningalgorithm, datas...  \n",
       "116  [machinelearn, machinelearningalgorithm, datas...  \n",
       "117  [datasci, datasciencejob, datasciencetrain, da...  \n",
       "118  [python, pythonprogram, pythonproject, pythonc...  \n",
       "\n",
       "[119 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7e7fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119 entries, 0 to 118\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Impressions         119 non-null    int64 \n",
      " 1   Comments            119 non-null    int64 \n",
      " 2   Shares              119 non-null    int64 \n",
      " 3   Likes               119 non-null    int64 \n",
      " 4   Caption             119 non-null    object\n",
      " 5   Hashtags            119 non-null    object\n",
      " 6   fullCaption         119 non-null    object\n",
      " 7   Tokenized_Text      119 non-null    object\n",
      " 8   Stemmed_Text        119 non-null    object\n",
      " 9   tokenizedCaptions   119 non-null    object\n",
      " 10  Tokenized_Hashtags  119 non-null    object\n",
      " 11  Stemmed_Hashtags    119 non-null    object\n",
      " 12  tokenizedHashtags   119 non-null    object\n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "captionDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd3857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionDF.to_csv(\"Datasets/cleaned-IG-data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
