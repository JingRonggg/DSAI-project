{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08750e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import plotly.express as px\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce86447",
   "metadata": {},
   "source": [
    "### We are using the dataset before bootstrapping to find the correlation between caption and `likes`, `comments`, `shares`, `impression` as if we were to bootstrap the data, there will not be any correlation anymore due to the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ebd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionDF = pd.read_csv(\"cleaned-IG-data.csv\", encoding = \"utf-8\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4ce817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>fullCaption</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>tokenizedCaptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3920</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>Here are some of the most important data visua...</td>\n",
       "      <td>#finance #money #business #investing #investme...</td>\n",
       "      <td>here are some of the most important data visua...</td>\n",
       "      <td>['important', 'data', 'visualizations', 'every...</td>\n",
       "      <td>['import', 'data', 'visual', 'everi', 'financi...</td>\n",
       "      <td>['important', 'data', 'visualization', 'every'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5394</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>Here are some of the best data science project...</td>\n",
       "      <td>#healthcare #health #covid #data #datascience ...</td>\n",
       "      <td>here are some of the best data science project...</td>\n",
       "      <td>['best', 'data', 'science', 'project', 'ideas'...</td>\n",
       "      <td>['best', 'data', 'scienc', 'project', 'idea', ...</td>\n",
       "      <td>['best', 'data', 'science', 'project', 'idea',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4021</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>Learn how to train a machine learning model an...</td>\n",
       "      <td>#data #datascience #dataanalysis #dataanalytic...</td>\n",
       "      <td>learn how to train a machine learning model an...</td>\n",
       "      <td>['learn', 'train', 'machine', 'learning', 'mod...</td>\n",
       "      <td>['learn', 'train', 'machin', 'learn', 'model',...</td>\n",
       "      <td>['learn', 'train', 'machine', 'learning', 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4528</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>213</td>\n",
       "      <td>Heres how you can write a Python program to d...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "      <td>heres how you can write a python program to d...</td>\n",
       "      <td>['heres', 'write', 'python', 'program', 'detec...</td>\n",
       "      <td>['here', 'write', 'python', 'program', 'detect...</td>\n",
       "      <td>['here', 'write', 'python', 'program', 'detect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2518</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>Plotting annotations while visualizing your da...</td>\n",
       "      <td>#datavisualization #datascience #data #dataana...</td>\n",
       "      <td>plotting annotations while visualizing your da...</td>\n",
       "      <td>['plotting', 'annotations', 'visualizing', 'da...</td>\n",
       "      <td>['plot', 'annot', 'visual', 'data', 'consid', ...</td>\n",
       "      <td>['plotting', 'annotation', 'visualizing', 'dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>13700</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>373</td>\n",
       "      <td>Here are some of the best data science certifi...</td>\n",
       "      <td>#datascience #datasciencejobs #datasciencetrai...</td>\n",
       "      <td>here are some of the best data science certifi...</td>\n",
       "      <td>['best', 'data', 'science', 'certifications', ...</td>\n",
       "      <td>['best', 'data', 'scienc', 'certif', 'choos', ...</td>\n",
       "      <td>['best', 'data', 'science', 'certification', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5731</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>Clustering is a machine learning technique use...</td>\n",
       "      <td>#machinelearning #machinelearningalgorithms #d...</td>\n",
       "      <td>clustering is a machine learning technique use...</td>\n",
       "      <td>['clustering', 'machine', 'learning', 'techniq...</td>\n",
       "      <td>['cluster', 'machin', 'learn', 'techniqu', 'us...</td>\n",
       "      <td>['clustering', 'machine', 'learning', 'techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>Clustering music genres is a task of grouping ...</td>\n",
       "      <td>#machinelearning #machinelearningalgorithms #d...</td>\n",
       "      <td>clustering music genres is a task of grouping ...</td>\n",
       "      <td>['clustering', 'music', 'genres', 'task', 'gro...</td>\n",
       "      <td>['cluster', 'music', 'genr', 'task', 'group', ...</td>\n",
       "      <td>['clustering', 'music', 'genre', 'task', 'grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>32695</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>549</td>\n",
       "      <td>Here are some of the best data science certifi...</td>\n",
       "      <td>#datascience #datasciencejobs #datasciencetrai...</td>\n",
       "      <td>here are some of the best data science certifi...</td>\n",
       "      <td>['best', 'data', 'science', 'certifications', ...</td>\n",
       "      <td>['best', 'data', 'scienc', 'certif', 'choos', ...</td>\n",
       "      <td>['best', 'data', 'science', 'certification', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>36919</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>443</td>\n",
       "      <td>175 Python Projects with Source Code solved an...</td>\n",
       "      <td>#python #pythonprogramming #pythonprojects #py...</td>\n",
       "      <td>175 python projects with source code solved an...</td>\n",
       "      <td>['python', 'projects', 'source', 'code', 'solv...</td>\n",
       "      <td>['python', 'project', 'sourc', 'code', 'solv',...</td>\n",
       "      <td>['python', 'project', 'source', 'code', 'solve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Impressions  Comments  Shares  Likes  \\\n",
       "0           3920         9       5    162   \n",
       "1           5394         7      14    224   \n",
       "2           4021        11       1    131   \n",
       "3           4528        10       7    213   \n",
       "4           2518         5       4    123   \n",
       "..           ...       ...     ...    ...   \n",
       "114        13700         2      38    373   \n",
       "115         5731         4       1    148   \n",
       "116         4139         0       1     92   \n",
       "117        32695         2      75    549   \n",
       "118        36919         5      26    443   \n",
       "\n",
       "                                               Caption  \\\n",
       "0    Here are some of the most important data visua...   \n",
       "1    Here are some of the best data science project...   \n",
       "2    Learn how to train a machine learning model an...   \n",
       "3    Heres how you can write a Python program to d...   \n",
       "4    Plotting annotations while visualizing your da...   \n",
       "..                                                 ...   \n",
       "114  Here are some of the best data science certifi...   \n",
       "115  Clustering is a machine learning technique use...   \n",
       "116  Clustering music genres is a task of grouping ...   \n",
       "117  Here are some of the best data science certifi...   \n",
       "118  175 Python Projects with Source Code solved an...   \n",
       "\n",
       "                                              Hashtags  \\\n",
       "0    #finance #money #business #investing #investme...   \n",
       "1    #healthcare #health #covid #data #datascience ...   \n",
       "2    #data #datascience #dataanalysis #dataanalytic...   \n",
       "3    #python #pythonprogramming #pythonprojects #py...   \n",
       "4    #datavisualization #datascience #data #dataana...   \n",
       "..                                                 ...   \n",
       "114  #datascience #datasciencejobs #datasciencetrai...   \n",
       "115  #machinelearning #machinelearningalgorithms #d...   \n",
       "116  #machinelearning #machinelearningalgorithms #d...   \n",
       "117  #datascience #datasciencejobs #datasciencetrai...   \n",
       "118  #python #pythonprogramming #pythonprojects #py...   \n",
       "\n",
       "                                           fullCaption  \\\n",
       "0    here are some of the most important data visua...   \n",
       "1    here are some of the best data science project...   \n",
       "2    learn how to train a machine learning model an...   \n",
       "3    heres how you can write a python program to d...   \n",
       "4    plotting annotations while visualizing your da...   \n",
       "..                                                 ...   \n",
       "114  here are some of the best data science certifi...   \n",
       "115  clustering is a machine learning technique use...   \n",
       "116  clustering music genres is a task of grouping ...   \n",
       "117  here are some of the best data science certifi...   \n",
       "118  175 python projects with source code solved an...   \n",
       "\n",
       "                                        Tokenized_Text  \\\n",
       "0    ['important', 'data', 'visualizations', 'every...   \n",
       "1    ['best', 'data', 'science', 'project', 'ideas'...   \n",
       "2    ['learn', 'train', 'machine', 'learning', 'mod...   \n",
       "3    ['heres', 'write', 'python', 'program', 'detec...   \n",
       "4    ['plotting', 'annotations', 'visualizing', 'da...   \n",
       "..                                                 ...   \n",
       "114  ['best', 'data', 'science', 'certifications', ...   \n",
       "115  ['clustering', 'machine', 'learning', 'techniq...   \n",
       "116  ['clustering', 'music', 'genres', 'task', 'gro...   \n",
       "117  ['best', 'data', 'science', 'certifications', ...   \n",
       "118  ['python', 'projects', 'source', 'code', 'solv...   \n",
       "\n",
       "                                          Stemmed_Text  \\\n",
       "0    ['import', 'data', 'visual', 'everi', 'financi...   \n",
       "1    ['best', 'data', 'scienc', 'project', 'idea', ...   \n",
       "2    ['learn', 'train', 'machin', 'learn', 'model',...   \n",
       "3    ['here', 'write', 'python', 'program', 'detect...   \n",
       "4    ['plot', 'annot', 'visual', 'data', 'consid', ...   \n",
       "..                                                 ...   \n",
       "114  ['best', 'data', 'scienc', 'certif', 'choos', ...   \n",
       "115  ['cluster', 'machin', 'learn', 'techniqu', 'us...   \n",
       "116  ['cluster', 'music', 'genr', 'task', 'group', ...   \n",
       "117  ['best', 'data', 'scienc', 'certif', 'choos', ...   \n",
       "118  ['python', 'project', 'sourc', 'code', 'solv',...   \n",
       "\n",
       "                                     tokenizedCaptions  \n",
       "0    ['important', 'data', 'visualization', 'every'...  \n",
       "1    ['best', 'data', 'science', 'project', 'idea',...  \n",
       "2    ['learn', 'train', 'machine', 'learning', 'mod...  \n",
       "3    ['here', 'write', 'python', 'program', 'detect...  \n",
       "4    ['plotting', 'annotation', 'visualizing', 'dat...  \n",
       "..                                                 ...  \n",
       "114  ['best', 'data', 'science', 'certification', '...  \n",
       "115  ['clustering', 'machine', 'learning', 'techniq...  \n",
       "116  ['clustering', 'music', 'genre', 'task', 'grou...  \n",
       "117  ['best', 'data', 'science', 'certification', '...  \n",
       "118  ['python', 'project', 'source', 'code', 'solve...  \n",
       "\n",
       "[119 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionDF = captionDF.drop('Unnamed: 0', axis = 1)\n",
    "captionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c2ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119 entries, 0 to 118\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Impressions        119 non-null    int64 \n",
      " 1   Comments           119 non-null    int64 \n",
      " 2   Shares             119 non-null    int64 \n",
      " 3   Likes              119 non-null    int64 \n",
      " 4   Caption            119 non-null    object\n",
      " 5   Hashtags           119 non-null    object\n",
      " 6   fullCaption        119 non-null    object\n",
      " 7   Tokenized_Text     119 non-null    object\n",
      " 8   Stemmed_Text       119 non-null    object\n",
      " 9   tokenizedCaptions  119 non-null    object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 9.4+ KB\n"
     ]
    }
   ],
   "source": [
    "captionDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc039493",
   "metadata": {},
   "source": [
    "### Finding Correlation of Hashtags and Likes/comments/shares/impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85996d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a168e229aed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtfidf_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptionDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combinedTokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtfidf_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         )\n\u001b[1;32m-> 2139\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1387\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1293\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1296\u001b[0m                     \u001b[1;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "captionDF['combinedTokens'] = captionDF['tokenizedCaptions'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(captionDF['combinedTokens'])\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Compute correlation matrix between TF-IDF features and impressions\n",
    "correlation_matrix = np.corrcoef(tfidf_df.values.T, captionDF['Impressions'])\n",
    "\n",
    "# Get correlation coefficients for each word\n",
    "word_correlations = correlation_matrix[:-1, -1]\n",
    "\n",
    "# Create a DataFrame to display word correlations\n",
    "word_correlation_df = pd.DataFrame({\n",
    "    'Word': tfidf_df.columns,\n",
    "    'Correlation_with_Impressions': word_correlations\n",
    "})\n",
    "\n",
    "# Sort DataFrame by correlation coefficient in descending order\n",
    "word_correlation_df = word_correlation_df.sort_values(by='Correlation_with_Impressions', ascending=False)\n",
    "\n",
    "print(word_correlation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df93006",
   "metadata": {},
   "source": [
    "### Finding Correlation of Caption words and Likes/comments/shares/impressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0bf9cf",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "### Conclusion: \n",
    "##### The captions & hashtag that can bring about the most impressions and likes/commets/shares are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65603b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
